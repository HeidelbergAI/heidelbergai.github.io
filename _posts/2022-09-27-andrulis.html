---
layout: post
title: "Human compatible world models across sizes, languages and modalities"
subtitle: "Jonas Andrulis, Constantin Eichenberg, Robert Baldock; Aleph Alpha"
custom_date: "September 27th 2022 @ 6pm"
date: 2022-05-18
background: '/img/posts/2022-09-27-andrulis-background.jpg'
future_date: True
layer_shift: True
---

Did you know there was an AI startup working on "General Artificial Intelligence" right here in Heidelberg?
<br>
Yes, there is! And we will have them with us at heidelberg.ai!<br><br>
We are excited to have Jonas Andrulis, Constantin Eichenberg and Robert Baldock,
<!-- Jonas Andrulis, Founder and CEO of Aleph Alpha -->
the CEO and research scientists of the startup
<a href="https://www.aleph-alpha.com" style="text-decoration: underline">
  Aleph Alpha
</a>
from Heidelberg,
present their work and insights on multimodal learners and world models in person at the DKFZ.
As an example of their work and goal towards making AI technologies accessible to a wide audience, they 
<a href="https://github.com/Aleph-Alpha/magma" style="text-decoration: underline">
open-sourced 
</a>
the MAGMA multimodal model, which can process images and text in any combination, this year. 
<!-- this year with the aim of making AI models usable for a wide audience. -->

<br>

<h2 class="section-heading">Abstract</h2>

<p>
  The generalizability and few-shot capabilities of large language models (LLM) like GPT-3 have opened up new possibilities for countless innovative apps. 
  LLMs demonstrate an impressive context and language understanding which enables them to solve problems that were previously intractable with deep learning. 
  This level of proficiency is based on the structure and knowledge extracted from a huge array of diverse and complex texts. 
  Up to this point, the application of large-scale language (pre-)training to the construction of multimodal models has been mostly limited to specialized tasks, 
  like visual QA or captioning, or it required expensive data annotation. 
  These attempts thus failed to make convincing use of the potential and flexibility of large language models with their hundreds of billions of parameters. 
  This is where we succeeded in building a 
  <a href="https://arxiv.org/abs/2112.05253" style="text-decoration: underline">
    fully self-supervised trained multimodal model
  </a> by combining an existing (self-build) multi-language LLM with a pre-trained image encoder. 
  We will discuss our approach of augmenting generative language models with additional modalities using adapter-based finetuning. 
  The language model weights remain unchanged during training, allowing for the transfer of encyclopedic knowledge and in-context learning abilities from language pretraining. 
  This approach makes multimodal enhancement efficient even for very large language models and adds world knowledge and context understanding previously only seen for language models. 
  We further discuss current work using the multimodal embedding for search, explainability and classification.
</p>
<h2 class="section-heading">Presenters</h2>
<p>
  <ul>
  <li>Jonas Andreas, CEO and founder of Aleph Alpha</li>
  <li>Constantin Eichenberg, Researcher at Aleph Alpha</li>
  <li>Robert Baldock, Senior researcher at Aleph Alpha</li>
  </ul>
</p>
<p>
  <a href="https://www.aleph-alpha.com" style="text-decoration: underline">
    Aleph Alpha
  </a>
  is an artificial intelligence research & development company from Heidelberg, Germany. Aleph Alpha aims to revolutionize the accessibility and usability of AI towards an era of Transformative Artificial Intelligence in Europe.
</p>
<div style="width:33%">
  <br>
  <center><a href="https://twitter.com/jonasandrulis"><img src="/img/posts/2022-09-27-jonas-andrulis-2.png" width="90%"></a> <br><br>
      <a href="https://twitter.com/jonasandrulis" style="text-decoration: underline">Jonas Andrulis</a>
  </center>
</div>
<!-- 
<div class="row">
    <div style="width:33%">
        <br>
        <center><a href="http://www.simonkohl.com"><img src="/img/people/simon.png" width="90%"></a> <br><br>
            <a href="http://www.simonkohl.com" style="text-decoration: underline">Simon Kohl</a>
        </center>
    </div>
    <div style="width:66%">
        <p>
        Simon is a Senior Research Scientist at DeepMind, where he works on AlphaFold2 and problems in structural biology. 
        Before joining DeepMind he was a PhD student at the German Cancer Research Center in Heidelberg, Germany, where he developed generative models for biomedical image segmentation.
        Broadly, Simon is interested in developing deep, often generative, neural networks for natural science and real world applications. 
        His research is often concerned with uncertainty quantification and the generation of multi-modal outputs in problems that allow multiple solutions.
        </p>
    </div>
</div> -->

<!-- Table with all important information in one Place! -->
<h2 class="section-heading">Event Info</h2>
<p>
Please help us plan ahead by registrating for the event at our 
<!-- ADD MEETUP LINK -->
<a href="https://www.meetup.com/heidelberg-artificial-intelligence-meetup/events/288268193/" style="text-decoration: underline">
  meetup event-site
</a>. <br>
After the event, there will be a social get-together with food and drinks courtesy of the Division of Medical Image Computing and Interactive Machine Learning Group at the DKFZ.
</p>
<!-- <div class="row">
    <center> -->
<style type="text/css">
    .tg  {border-collapse:collapse;border-spacing:0;}
    .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
      overflow:hidden;padding:10px 5px;word-break:normal;}
    .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
      font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
    .tg .tg-0lax{text-align:left;vertical-align:top}
    </style>
    <table class="tg">
    <thead>
      <tr>
        <th class="tg-0lax">What?</th>
        <th class="tg-0lax">{{ page.title}}</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="tg-0lax">Who?</td>
        <td class="tg-0lax">{{ page.subtitle}}</td>
      </tr>
      <tr>
        <td class="tg-0lax">When?</td>
        <td class="tg-0lax">{{ page.custom_date}}</td>
      </tr>
      <tr>
        <td class="tg-0lax">Where?</td>
        <td class="tg-0lax">DKFZ Communication Center (K1+K2), Im Neuenheimer Feld 280</td>
      </tr>
      <!-- <tr>
        <td class="tg-0lax">Livestream</td>
        <td class="tg-0lax"><a href="https://us02web.zoom.us/j/5824790176">Zoom</a></td>
      </tr> -->
      <tr>
        <td class="tg-0lax">Registration</td>
        <td class="tg-0lax">
          <a href="https://www.meetup.com/heidelberg-artificial-intelligence-meetup/events/288268193/" style="text-decoration: underline">
            meetup event-site
          </a>
          </td>
      </tr>
    </tbody>
    </table>
  <h2 class="section-heading">Corona rules</h2>
  <p>
      We are happy to see that so many of you are interested in this event! 
    To allow as many people as possible to attend it, the following rules apply:
    Attendance requires wearing a FFP2 mask is mandatory throughout the whole event.
  </p>
  <!-- <p>
    After the event, we will walk over to <a href="https://goo.gl/maps/MSaZcy9eRngD6z9B9">‘Park an der Uferstraße’</a> to discuss and share ideas with one another over a few beverages.
  </p> -->
    <!-- </center> -->
<!-- </div> -->
<!-- <h2 class="section-heading">Event's recording</h2><br>

<iframe width="800" height="480" src="https://www.youtube.com/embed/At4rhuKu84o" frameborder="0"
    allow="autoplay; encrypted-media" allowfullscreen></iframe> -->